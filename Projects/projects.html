<!DOCTYPE html>
<html lang="en">

<head>
    <title>Anton Bredenbeck - Projects</title>
    <meta name="description" content="Anton Bredenbeck, Projects.">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <link href="../main_files/css" rel="stylesheet">
    <link rel="stylesheet" href="../main_files/style.css">
    
    <style>
        /* Responsive text scaling - works with existing stylesheet */
        body {
            font-size: clamp(0.875rem, 1.2vw + 0.5rem, 1rem);
        }
        
        h1 {
            font-size: clamp(1.5rem, 2vw + 1rem, 2rem);
        }
        
        h2 {
            font-size: clamp(1.25rem, 1.5vw + 0.75rem, 1.75rem);
        }
        
        papertitle {
            font-size: clamp(1rem, 1.3vw + 0.5rem, 1.25rem) !important;
        }
        
        #detail, #summary {
            font-size: clamp(0.875rem, 1.2vw + 0.4rem, 1rem);
        }
        
        p, a, em {
            font-size: inherit;
        }
        
        /* Ensure tables don't overflow */
        table {
            width: 100%;
            table-layout: auto;
        }
        
        /* Make images responsive */
        img {
            max-width: 100%;
            height: auto;
        }
        
        /* Adjust container max-width to work better */
        .container {
            max-width: 1000px;
        }
        
        /* Only stack layout on very small screens */
        @media (max-width:600px) {
            table.project-table tr {
                display: block;
            }
            
            table.project-table td {
                display: block;
                width: 100% !important;
                padding: 10px 0 !important;
            }
            
            table.project-table td img {
                max-width: 800px;
                margin: 0 auto;
                display: block;
            }
        }
    </style>

</head>

<body>
    <div class="container">
        <a href="../index.html" class="toggler"><button id="home_button">Home</button></a> 
        <table width="1000px" cellspacing="0" cellpadding="0">
            <tr>
                <td>
                    <div style="height:20px;"></div>

                    <!-- Research Section -->
                    <table width="100%" cellspacing="0" cellpadding="0">
                        <tr>
                            <td>
                                <h1>Research</h1>
                            </td>
                        </tr>
                    </table>

                    <table width="100%" class="project-table" cellspacing="0" cellpadding="10">
                        
                        <tr>
                            <td width="35%">
                                <img src="./files/feely_the_drone/feely_overview.jpg" width="300">
                            </td>
                            <td width="60%">
                                <div id="summary">
                                    <papertitle>Aerial Tactile Perching via an Anthropomorphic Hand with Embodied Soft Tactile Receptors</papertitle>
                                    <div style="height:5px;"></div>            
                                    <a href="../index.html" target="_blank">Anton Bredenbeck</a>,
                                    <a href="https://www.linkedin.com/in/ajadoenathmisier/" target="_blank">Anish Jadoenathmisier</a>,
                                    <a href="https://scholar.google.com/citations?user=O7snlrcAAAAJ&hl=en" target="_blank">Salua Hamaza</a>
                                    <div style="height:5px;"></div>
                                    <p style="color:#000000">
                                        <em>[UNDER REVIEW 2026]:</em>
                                        <a href="./feely_the_drone.html" target="_blank">website</a> /
                                        <a href="https://antbre.github.io/Projects/ToDo.html" target="_blank">pre-print</a> / 
                                        <a href="github.com/BioMorphic-Intelligence-Lab/feely_drone" target="_blank">github</a>   
                                    </p>
                                <div id="detail">
                                    A lightweight MAV uses tactile sensors and a compliant gripper to robustly perch on various targets without requiring precise target knowledge.
                                </div>
                            </div>
                            </td>
                        </tr>


                        <tr>
                            <td width="35%">
                                <img src="./files/tether_inertial/platform_rover.jpg" width="300" alt="Tether-Inertial Localization">
                            </td>
                            <td width="60%">
                                <div id="summary">
                                    <papertitle>Tether-Inertial Localization for Drones on Mars</papertitle>
                                    <div style="height:5px;"></div>
                                    <a href="https://www.linkedin.com/in/dielof-van-loon-a33629161/" target="_blank">D.I. van Loon</a>,
                                    <a href="../index.html" target="_blank">Anton Bredenbeck</a>,
                                    <a href="https://www.linkedin.com/in/lennart-puck-40a829227" target="_blank">L. Puck</a>,
                                    <a href="https://www.linkedin.com/in/martin-azkarate-esa-robotics/" target="_blank">M. Azkarate</a>,
                                    <a href="https://scholar.google.com/citations?user=O7snlrcAAAAJ&hl=en" target="_blank">Salua Hamaza</a>
                                    <div style="height:5px;"></div>
                                    <p style="color:#000000">
                                        <em>[UNDER REVIEW 2026]:</em>
                                        <a href="./tether_inertial_mars.html" target="_blank">website</a> /
                                        <a href="https://antbre.github.io/Projects/ToDo.html" target="_blank">pre-print</a> / 
                                        <a href="https://youtu.be/YMYKxUlA4uo" target="_blank">video</a> 
                                    </p>
                                <div id="detail">
                                    A tethered drone estimates its pose relative to a base from tether length and angles using a catenary model and GP residual correction—efficient, non-drifting, and accurate.
                                </div>
                            </div>
                            </td>
                        </tr>

                        <tr>
                            <td width="35%">
                                <img src="./files/colliding_drone/overview_figure.png" width="300">
                            </td>
                            <td width="60%">
                                <div id="summary">
                                    <papertitle>A Tactile Feedback Approach to Path Recovery after High-Speed Impacts for Collision-Resilient Drones</papertitle>
                                    <div style="height:5px;"></div>            
                                    <a href="../index.html" target="_blank">Anton Bredenbeck</a>,
                                    <a href="https://hiperlab.berkeley.edu/members/teaya-yang/" target="_blank">Teaya Yang</a>,
                                    <a href="https://scholar.google.com/citations?user=O7snlrcAAAAJ&hl=en" target="_blank">Salua Hamaza</a>,
                                    <a href="https://scholar.google.com/citations?user=yQxs7qUAAAAJ" target="_blank">Mark W. Mueller</a>
                                    <div style="height:5px;"></div>
                                    <p style="color:#000000">
                                        <em>MDPI Drones, December 2025:</em>
                                        <a href="./colliding_drone.html" target="_blank">website</a> /
                                        <a href="https://arxiv.org/abs/2410.14249" target="_blank">paper</a> / 
                                        <a href="https://youtu.be/CMrgngliWX0?si=-yuezrYxXJorvMKs" target="_blank">video</a> /
                                        <a href="https://github.com/BioMorphic-Intelligence-Lab/colliding-drone" target="_blank">github</a>   
                                    </p>
                                <div id="detail">
                                    A resource limited MAV uses binary tactile sensors to recover from high-speed collisions and adjust the a-priori planned path based on the collision location. 
                                </div>
                            </div>
                            </td>
                        </tr>

                        <tr>
                            <td width="35%">
                                <img src="./files/blind_navigation/overview_figure.png" width="300">
                            </td>
                            <td width="60%">
                                <div id="summary">
                                    <papertitle>Embodying Compliant Touch in Aerial Manipulation for Blind Navigation</papertitle>
                                    <div style="height:5px;"></div>            
                                    <a href="../index.html" target="_blank">Anton Bredenbeck</a>,
                                    <a href="https://scholar.google.com/citations?user=7RAU5jYAAAAJ&hl=en" target="_blank">Cosimo Della Santina</a>,
                                    <a href="https://scholar.google.com/citations?user=O7snlrcAAAAJ&hl=en" target="_blank">Salua Hamaza</a>
                                    <div style="height:5px;"></div>
                                    <p style="color:#000000">
                                        <em>IEEE Robotics and Automation Letters (RA-L), December 2024:</em>
                                        <a href="./blind_navigation.html" target="_blank">website</a> /
                                        <a href="https://www.researchgate.net/publication/386415025_Embodying_Compliant_Touch_on_Drones_for_Aerial_Tactile_Navigation" target="_blank">paper</a> / 
                                        <a href="https://youtu.be/dhEn9IjKmQA" target="_blank">video</a> /
                                        <a href="https://github.com/bioMorphic-Intelligence-Lab/tactile-drone" target="_blank">github</a> 
                                    </p>
                                <div id="detail">
                                    A MAV navigates in unknown environments using only contact information extracted from a compliant, finger-like interaction tool.
                                </div>
                            </div>
                            </td>
                        </tr>
                        
                        <tr>
                            <td width="35%">
                                <img src="./files/tactile_odometry/tactile_odometry.png" width="300">
                            </td>
                            <td width="60%">
                                <div id="summary">
                                    <papertitle>Tactile Odometry in Aerial Physical Interaction</papertitle>
                                    <div style="height:5px;"></div>
                                    <a href="https://www.researchgate.net/profile/Micha-Schuster" target="_blank">Micha Schuster*</a>,
                                    <a href="../index.html" target="_blank">Anton Bredenbeck*</a>,
                                    <a href="https://www.researchgate.net/profile/Michael-Beitelschmidt" target="_blank">Michael Beitelschmidt</a>,
                                    <a href="https://scholar.google.com/citations?user=O7snlrcAAAAJ&hl=en" target="_blank">Salua Hamaza</a>
                                    <div style="height:5px;"></div>
                                    <p style="color:#000000">
                                        <em>International Conference on Intelligent Robots and Systems (IROS)</em>, October 2024:
                                        <a href="./tactile_odometry_drone.html" target="_blank">website</a> /
                                        <a href="https://www.researchgate.net/publication/383065161_Tactile_Odometry_in_Aerial_Physical_Interaction" target="_blank">paper</a> / 
                                        <a href="https://youtu.be/iH8SYRLM8FM" target="_blank">video</a> /
                                        <a href="https://github.com/bioMorphic-Intelligence-Lab/tactile-odometry-drone" target="_blank">github</a>          
                                    </p>
                                <div id="detail">
                                    Reconstructing MAV odometry from contact information using a trackball mounted on a compliant 
                                    contact interface. 
                                </div>
                            </div>
                            </td>
                        </tr>
                        <tr>
                            <td width="35%">
                                <img src="./files/ff_trajectories/reacsa.png" width="300">
                            </td>
                            <td width="60%">
                                <div id="summary">
                                    <papertitle>Trajectory Optimization and Following for a Three Degrees of Freedom Overactuated Floating Platform</papertitle>
                                    <div style="height:5px;"></div>
                                    <a href="../index.html" target="_blank">Anton Bredenbeck</a>,
                                    <a href="https://scholar.google.com/citations?user=M5Pp5yYAAAAJ&hl=en" target="_blank">Shubham Vyas</a>,
                                    <a href="https://scholar.google.com/citations?user=R07G1FQAAAAJ&hl=en" target="_blank">Dorit Borrmann</a>,
                                    <a href="https://scholar.google.com/citations?user=Aw-nkicAAAAJ&hl=en" target="_blank">Miguel Olivares-Mendez</a>,
                                    <a href="https://scholar.google.com/citations?user=0KilZDkAAAAJ&hl=en" target="_blank">Andreas Nüchter</a>,
                                    <div style="height:5px;"></div>
                                    <p style="color:#000000">
                                        <em>International Conference on Intelligent Robots and Systems (IROS)</em>, October 2022:
                                        <a href="https://ieeexplore.ieee.org/document/9981294" target="_blank">paper</a> / 
                                        <a href="https://www.youtube.com/watch?v=1A5xJVEAU9w" target="_blank">video</a>
                                    </p>
                                <div id="detail">
                                    Optimal control of a free-floating platform for the simulation of micro-gravity environments at the Orbital Robotics Lab at the European Space Agency (ESA).
                                </div>
                            </div>
                            </td>
                        </tr>
                    </table>

                    <hr>

                    <!-- Projects Section -->
                    <h2>Other projects</h2>
                    <table width="100%" class="project-table" cellspacing="0" cellpadding="10">
                        <tr>
                            <td width="35%">
                                <img src="./files/edubot.gif" width="300">
                            </td>
                            <td width="60%">
                                <div id="summary">
                                    <p class="papertitle">EduBot: A ROS 2 library for education in robotic manipulation</p>
                                    <a href="https://github.com/bioMorphic-Intelligence-Lab/edubot" target="_blank">GitHub</a>
                                    <br>
                                    <div style="height:10px;"></div>
                                    <div id="detail">
                                    A small ROS 2 library that we use for teaching purposes at the Biomorphic Intelligence Lab. 
                                    In particular, it covers the hardware interface to a motor control board as well as ROS 2 based interface and a RVIZ 2 based visualization.
                                    </div>
                                </div>
                            </td>
                        </tr>

                        <tr>
                            <td width="35%">
                                <img src="./files/primex120-perspective-638.webp" width="300">
                            </td>
                            <td width="60%">
                                <div id="summary">
                                    <p class="papertitle">Unified Optitrack Clients</p>
                                    <a href="https://github.com/tudelft/UnifiedOptitrackClients" target="_blank">GitHub</a> 
                                    co-maintained with <a href="https://github.com/tblaha" target="_blank">Till Blaha</a>
                                    <br>
                                    <div style="height:10px;"></div>
                                    <div id="detail">
                                        A unified C++ client for reading data from an OptiTrack motion capture system and
                                        publishing it in various formats. The implementation emphasizes minimalism, speed,
                                        and extensibility. It supports publishing data with applied rotations via UDP streams,
                                        ROS 2 topics, and PX4-compatible ROS 2 topics, among others.
                                    </div>
                                </div>
                            </td>
                        </tr>
                    </table>
                    <hr>
                    <!-- Credit -->
                    <table width="100%" cellspacing="0" cellpadding="0" style="float: right; text-align: right;font-size: 12px;">
                        <tr>
                            <td>
                                Last updated: July 2024<br>
                                <a href="https://www.cs.cmu.edu/~sudhars1/" target="_blank">Adapted from Sudharshan Suresh</a>
                            </td>
                        </tr>
                    </table>
         

                </td>
            </tr>

        </table>

        <div class="dark-mode-toggler">
            <input type="checkbox" id="toggler" checked>
            <label for="toggler" aria-label="Toggler for Dark Mode"></label>
        </div>

    </div>

    <script src="../main_files/script.js"></script>
</body>
</html>